from __future__ import annotations

import glob
import re
from collections.abc import Mapping
from enum import unique
from pathlib import Path
from types import MappingProxyType
from typing import Any

import dask.array as da
import numpy as np
import spatialdata as sd
from numpy.typing import NDArray
from ome_types.model import Pixels, UnitsLength
from spatialdata import SpatialData
from spatialdata._logging import logger
from spatialdata.transformations import Identity
from spatialdata_io._constants._enum import ModeEnum
from xarray import DataArray, DataTree

from harpy.utils.utils import _make_list

try:
    from bioio import BioImage
except ImportError:
    logger.warning("Module 'bioio' not installed, please install 'bioio' if you want to use 'harpy.io.macsima'.")


@unique
class MacsimaKeys(ModeEnum):
    """Keys for *MACSima* formatted dataset."""

    # images
    IMAGE_OMETIF = ".tif"
    CHANNEL_NAMES = "channel_names"
    CYCLE = "Cycle"
    SCANTYPE = "ScanType"
    ROI_ID = "RoiId"
    ROI_ID_deprecated = "ROI ID"
    SCREENS = "screens"
    REAGENTS = "reagents"


def macsima(
    path: str | Path | list[str] | list[Path],
    c_subset: list[str] = None,
    remove_bleached: bool = True,
    remove_dapi: bool = True,
    transformations: bool = False,
    chunks: int = None,  # chunks is currently ignored by spatialdata
    imread_kwargs: Mapping[str, Any] = MappingProxyType({}),
    image_models_kwargs: Mapping[str, Any] = MappingProxyType({}),
    output: str | Path | None = None,
    overwrite: bool = False,
) -> SpatialData:
    """
    Read *MACSima* formatted dataset.

    This function reads images from a MACSima cyclic imaging experiment.

    The channel names will follow the following format:
    **cycle_scantype_channelname_roiid_reagent**

    .. seealso::

        - `MACSima output <https://application.qitissue.com/getting-started/naming-your-datasets>`_.

    Parameters
    ----------
    path
        Path, or list of paths, to the directory/directories containing the data.
        Directory should contain the preprocessed `.tif` files as generated by MACS IQ VIEW.
    c_subset
        Channel names to consider.
        Elements of `c_subset` that are in one of `cycle_scantype_channelname_roiid_reagent`, will be considered.
        E.g if `c_subset=['DAPI']` and  `cycle_scantype_channelname_roiid_reagent = 01_B_DAPI_001_DAPI`,
        then channel `01_B_DAPI_001_DAPI` will be retained.
    remove_bleached
        If set to `True` will remove all channels of scantype `'B'` (=bleached).
    remove_dapi
        If set to `True` will remove all dapi channels for which cycle number>0.
    transformations
        Whether to add a transformation from pixels to microns to the image.
    imread_kwargs
        Keyword arguments passed to :func:`bioio.BioImage`.
    image_model_kwargs
        Keyword arguments to pass to the image models.
        E.g. "chunks" or "scale_factors".
    output
        The path where the resulting `SpatialData` object will be backed. If `None`, it will not be backed to a zarr store.
    overwrite
        If set to `True` will overwrite the zarr store at `output`. Ignored if output is `None`.

    Returns
    -------
    :class:`spatialdata.SpatialData`

    Examples
    --------
    >>> sdata = macsima(
    ...     path="path/to/your/tiff/files", # creates one image layer
    ...     c_subset=["DAPI", "CD43"],
    ...     image_model_kwargs={"chunks": (1, 3000, 3000)},
    ... )
    >>> sdata = macsima(
    ...     path=["path/to/your/tiff/files","another_path/to/your/tiff/files"], # creates two image layers
    ...     c_subset=["DAPI", "CD43"],
    ...     image_model_kwargs={"chunks": (1, 3000, 3000)},
    ... )
    """
    path = _make_list(path)
    sdata = sd.SpatialData()
    for _path in path:
        image_name, se = _macsima(
            _path,
            c_subset=c_subset,
            remove_bleached=remove_bleached,
            remove_dapi=remove_dapi,
            transformations=transformations,
            chunks=chunks,
            imread_kwargs=imread_kwargs,
            image_models_kwargs=image_models_kwargs,
        )
        sdata[image_name] = se

    if output is not None:
        sdata.write(output, overwrite=overwrite)
        sdata = sd.read_zarr(sdata.path)

    return sdata


def _macsima(
    path: str | Path,
    c_subset: list[str] = None,
    remove_bleached: bool = True,
    remove_dapi: bool = True,
    transformations: bool = False,
    chunks: int = None,  # chunks is currently ignored by spatialdata
    imread_kwargs: Mapping[str, Any] = MappingProxyType({}),
    image_models_kwargs: Mapping[str, Any] = MappingProxyType({}),
) -> tuple[str, DataArray | DataTree]:
    """See Docstring of macsima."""
    # chunks not correctly passed to sd.models.Image2DModel.parse in case scale_factors is not None, so we rechunk ourself.
    if "chunks" in image_models_kwargs.keys():
        chunks = image_models_kwargs["chunks"]
    else:
        chunks = None
    path_list = glob.glob(f"{path}/*{MacsimaKeys.IMAGE_OMETIF}")
    if not path_list:
        raise ValueError(f"Cannot determine data set, expecting '*{MacsimaKeys.IMAGE_OMETIF}' files in {path}.")
    imgs = [BioImage(img_path, **imread_kwargs) for img_path in path_list]

    image_name = imgs[0].ome_metadata.experiments[0].description

    metadata = [_get_metadata(_img) for _img in imgs]
    roi = [item[3] for item in metadata]
    if roi[0] is not None:
        assert all(x == roi[0] for x in roi), (
            f"Extracted ROI ID not equal for all '{MacsimaKeys.IMAGE_OMETIF}' files found in '{path}'."
        )
        roi_id = roi[0]
        to_coordinate_system = f"global_{roi_id}"
        image_name = f"{image_name}_{roi_id}"
    else:
        to_coordinate_system = "global"

    if remove_bleached:
        metadata_imgs = [
            (m, i)
            for m, i in zip(metadata, imgs, strict=True)
            if m[1] is None or m[1] != "B"  # we keep if scantype is None
        ]
        metadata, imgs = zip(*metadata_imgs, strict=True) if metadata_imgs else ([], [])
        if not metadata:
            raise ValueError(
                "Resulting number of channels after removing channels of scantype 'B'(=bleached) is zero. "
                "Consider setting the parameter 'remove_bleached' to 'False'."
            )

    if remove_dapi:
        metadata_imgs = [
            (m, i)
            for m, i in zip(metadata, imgs, strict=True)
            if m[2] is None
            or m[0] is None
            or m[2] != "DAPI"
            or (m[2] == "DAPI" and m[0] == "0")  # we keep only first round DAPI
        ]
        metadata, imgs = zip(*metadata_imgs, strict=True) if metadata_imgs else ([], [])
        if not metadata:
            raise ValueError(
                "Resulting number of channels after removing DAPI channels (from cycle round i with i>0), is zero. "
                "Consider setting the parameter 'remove_dapi' to 'True'."
            )

        # remove all dapi not collected in first cycle

    names = ["_".join([part for part in name_parts if part]) for name_parts in metadata]
    number_pattern = re.compile(r"^\d+")
    # sort by cycle number
    combined_sorted = sorted(zip(names, imgs, strict=True), key=lambda x: int(number_pattern.match(x[0]).group()))
    names, imgs = zip(*combined_sorted, strict=True)
    names = [_name.strip("_") for _name in names]  # macsima adds these trailing _ to reagents.

    if c_subset:
        matched = []
        for item in names:
            match = False
            for _c_subset in c_subset:
                if _case_insensitive_in(_c_subset, item):
                    matched.append(True)
                    match = True
                    break
            if not match:
                matched.append(False)

        if not any(matched):
            raise ValueError(f"List of channels to consider is empty after subsetting by {c_subset}")

        names = [v for v, m in zip(names, matched, strict=True) if m]
        imgs = [v for v, m in zip(imgs, matched, strict=True) if m]

    # get physical units:
    pixels_to_microns = _parse_physical_size(pixels=imgs[0].ome_metadata.images[0].pixels)
    # sanity check (physical size of all images should be the same for one ROI)
    for _img in imgs:
        if pixels_to_microns != _parse_physical_size(_img.ome_metadata.images[0].pixels):
            raise ValueError("Physical units of all images in a ROI should be the same.")
    if imgs[0].dims.order != "TCZYX":
        raise ValueError("Dimension is expected to be 'TCZYX'.")

    arrays = [_img.get_image_dask_data() for _img in imgs]
    translations = _get_translations(imgs)
    sizes = np.array([_arr.shape[-2:] for _arr in arrays])

    # get chunksize from largest array to avoid irregular chunking
    # get some sane chunksizes for case chunks is None (prevent irregular chunking due to padding)
    if chunks is None:
        max_y_idx, max_x_idx = np.argmax(sizes, axis=0)
        _, _, _, chunksize_y, _ = arrays[max_y_idx].chunksize
        _, _, _, _, chunksize_x = arrays[max_x_idx].chunksize

    # resulting size after padding with translation will be done:
    sizes_trans = sizes + translations
    # resulting max sizes after padding with translation will be done:
    max_y, max_x = np.max(sizes_trans, axis=0)

    padded_arrays = []
    for _arr, _translation, _size in zip(arrays, translations, sizes_trans, strict=True):
        _arr = _arr.squeeze((0, 2))  # squeeze T and Z dimension
        pad_y_prepend = _translation[0]
        pad_x_prepend = _translation[1]

        pad_y_append = max_y - _size[0]
        pad_x_append = max_x - _size[1]

        pad_width = (
            (0, 0),  # C
            (pad_y_prepend, pad_y_append),  # Y
            (pad_x_prepend, pad_x_append),  # X
        )
        _arr = da.pad(_arr, pad_width, mode="constant", constant_values=0)
        if chunks is None:
            _arr = _arr.rechunk((1, chunksize_y, chunksize_x))
        padded_arrays.append(_arr)

    array = da.concatenate(padded_arrays, axis=0)

    if chunks is not None:
        array = array.rechunk(chunks)

    t_pixels_to_microns = (
        sd.transformations.Scale([pixels_to_microns, pixels_to_microns], axes=("x", "y"))
        if transformations
        else Identity()
    )

    se = sd.models.Image2DModel.parse(
        array,
        dims=["c", "y", "x"],
        c_coords=names,
        transformations={
            to_coordinate_system: t_pixels_to_microns,
        },
        **image_models_kwargs,
    )

    # spatialdata only allows alphanumeric and _ in the name
    image_name = _clean_string(image_name)

    return image_name, se


def _get_structured_annotations(img: BioImage, metadata_key: str) -> str | None:
    structured_annotations = img.ome_metadata.structured_annotations
    value = [item.value[metadata_key] for item in structured_annotations if item.value[metadata_key] is not None]
    if not value:
        return None
    assert all(x == value[0] for x in value), (
        f"Structured annotations for key '{metadata_key}' are not equal "
        f"(found '{value}') for object of type '{type(img).__name__}': {img}."
    )
    return value[0]


def _get_metadata(img: BioImage) -> list[str | None]:
    cycle = _get_structured_annotations(img, metadata_key=MacsimaKeys.CYCLE)
    # check that cycle is not None
    assert cycle is not None, (
        f"'{MacsimaKeys.CYCLE}' could not be found in metadata for object of type '{type(img).__name__}': {img}"
    )
    # we allow scantype to be None (i.e. not found in structured annotations of ome metadata)
    scantype = _get_structured_annotations(img, metadata_key=MacsimaKeys.SCANTYPE)
    channel_name = getattr(img, MacsimaKeys.CHANNEL_NAMES, None)
    if channel_name is None:
        raise AttributeError(
            f"Attribute '{MacsimaKeys.CHANNEL_NAMES}' not found for object of type '{type(img).__name__}': {img}"
        )
    assert len(channel_name) == 1, (
        f"There should be exactly one channel specified in metadata, but found '{channel_name}'."
    )
    channel_name = channel_name[0]
    if not channel_name:
        raise ValueError(
            f"'{MacsimaKeys.CHANNEL_NAMES}' is not specified in metadata "
            f"for object of type '{type(img).__name__}': {img}"
        )
    # get the reagents used from ome metadata if they can be found in ome metadata
    reagents = None
    if hasattr(img.ome_metadata, MacsimaKeys.SCREENS):
        screens = getattr(img.ome_metadata, MacsimaKeys.SCREENS)
        assert len(screens) == 1, (
            f"There should be exactly one '{MacsimaKeys.SCREENS}' specified in ome metadata, "
            f"but found '{screens}' for object of type '{type(img).__name__}': {img}."
        )
        screens = screens[0]
        reagents = getattr(screens, MacsimaKeys.REAGENTS, None)
        if reagents:
            assert len(reagents) == 1, (
                f"There should be exactly one '{MacsimaKeys.REAGENTS}' "
                f"specified in ome metadata, but found '{reagents}' for object of type '{type(img).__name__}': {img}."
            )
            reagents = reagents[0].name
    roi_id = _get_structured_annotations(img, metadata_key=MacsimaKeys.ROI_ID) or _get_structured_annotations(
        img, metadata_key=MacsimaKeys.ROI_ID_deprecated
    )
    return [cycle, scantype, channel_name, roi_id, reagents]


def _parse_physical_size(pixels: Pixels | None = None) -> float:
    """Parse physical size from OME-TIFF to micrometer."""
    logger.debug(pixels)
    if pixels.physical_size_x_unit != pixels.physical_size_y_unit:
        logger.error("Physical units for x and y dimensions are not the same.")
        raise NotImplementedError
    if pixels.physical_size_x != pixels.physical_size_y:
        logger.error("Physical sizes for x and y dimensions are the same.")
        raise NotImplementedError
    # convert to micrometer if needed
    if pixels.physical_size_x_unit == UnitsLength.NANOMETER:
        physical_size = pixels.physical_size_x / 1000
    elif pixels.physical_size_x_unit == UnitsLength.MICROMETER:
        physical_size = pixels.physical_size_x
    else:
        logger.error(f"Physical unit not recognized: '{pixels.physical_size_x_unit}'.")
        raise NotImplementedError
    return float(physical_size)


def _clean_string(input_string: str) -> str:
    """Replace all non-alphanumeric characters with '_', and replace ' ' with '-'."""
    output_string = re.sub(r"[^a-zA-Z0-9_]", "_", input_string)
    return output_string


def _get_translations(imgs: list[BioImage]) -> NDArray:
    # get the translations in y and x
    translations = []
    for _img in imgs:
        translation_y = 0
        translation_x = 0
        if not hasattr(_img.ome_metadata, "images"):
            logger.info("No metadata found for position, assuming position is 0,0.")
            translations.append(0, 0)
            continue
        _images = _img.ome_metadata.images
        assert len(_images) == 1  # replace with ValueError
        if not hasattr(_images[0].pixels, "planes"):
            logger.info("No metadata found for position, assuming position is 0,0.")
            translations.append(0, 0)
            continue
        _planes = _images[0].pixels.planes
        assert len(_planes) == 1  # replace with ValueError
        if not hasattr(_planes[0], "position_y") or not hasattr(_planes[0], "position_x"):
            logger.info("No metadata found for position, assuming position is 0,0.")
            translations.append(0, 0)
            continue
        translation_y = _planes[0].position_y
        translation_x = _planes[0].position_x
        translations.append((translation_y, translation_x))

    translations = np.array(translations)
    mins = translations.min(axis=0)
    return translations - mins


def _case_insensitive_in(a: str, b: str) -> bool:
    pattern = re.compile(re.escape(a), re.IGNORECASE)
    return bool(pattern.search(b))
